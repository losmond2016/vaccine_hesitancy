{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77466a9",
   "metadata": {},
   "source": [
    "# Neural Network Modelling & SMOTE under/over sampling\n",
    "\n",
    "This notebook presents an investigation into the impact on results of using a Multi-layer Perceptron (MLP) neural network models to predict Vaccine willingness on the Wave 1 data (i.e. does the use of neural network modelling improve accuracy/precision/recall scores).\n",
    "\n",
    "Furthermore, the SMOTE oversampling of minority class target groups is complemented by undersampling of the majority classes, to explore whether a mixed over/under sampling approach has a significant impact on model accuracy.\n",
    "\n",
    "The notebook is split into the following sections:\n",
    "\n",
    "- Package imports, data loading & pre-model processing\n",
    "- MLP and Logistic Regression Modelling\n",
    "- Summary of Findings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74c546",
   "metadata": {},
   "source": [
    "**Package imports and premodel processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f3d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Package imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import collections\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from scikitplot.decomposition import plot_pca_component_variance\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from scikitplot.metrics import plot_roc\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d2cc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9587, 87)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Import\n",
    "data = pd.read_csv(\"C:/Users/laure/OneDrive/Documents/Personal Admin Files/Stats or Career Stuff/General Assembly/Course Notes/Capstone Folder/Cleaned_data/wave_1_vaccine_intention_data.csv\")\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9709f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMREG_East Midlands\n",
      "DEMSEX_Female\n",
      "DEMEDU_0-4 GCSE, O-levels, or equivalents\n",
      "DEMWRK_Looking after the home\n",
      "DEMREL_Atheist or agnostic\n",
      "DEMINC_Over £100,000\n",
      "COV_SHIELD_No\n",
      "COV_TRUST_1_0\n",
      "COV_TRUST_2_0\n",
      "COV_TRUST_3_0\n",
      "COV_TRUST_4_0\n",
      "COV_TRUST_5_0\n",
      "COV_TRUST_6_0\n",
      "COV_TRUST_7_0\n",
      "COV_TRUST_8_0\n",
      "COV_TRUST_9_0\n",
      "COV_TRUST_10_0\n",
      "COV_TRUST_11_0\n",
      "COV_TRUST_12_0\n",
      "COV_TRUST_13_0\n"
     ]
    }
   ],
   "source": [
    "# Preparation of the data for modelling - manually dropping first dummy columns using feature list and total column list\n",
    "\n",
    "# Creation of total column list\n",
    "w1columns = []\n",
    "for column in data.columns:\n",
    "    w1columns.append(column)\n",
    "    \n",
    "# Creation of var_list\n",
    "var_list = ['DEMAGE', 'VAC_DEC',  'COV_KNOWL_1', 'COV_KNOWL_2',\n",
    "     'COV_KNOWL_3', 'COV_KNOWL_4', 'COV_KNOWL_5', 'COV_KNOWL_6',\n",
    "     'COV_KNOWL_7', 'DREAD', 'ANX_1', 'ANX_2', 'ANX_3', 'ANX_4', 'ANX_5',\n",
    "     'ANX_6', 'DEMREG_East of England',\n",
    "     'DEMREG_Greater London', 'DEMREG_North East', 'DEMREG_North West',\n",
    "     'DEMREG_Northern Ireland', 'DEMREG_Scotland', 'DEMREG_South East',\n",
    "     'DEMREG_South West', 'DEMREG_Wales', 'DEMREG_West Midlands',\n",
    "     'DEMREG_Yorkshire and The Humber', 'DEMSEX_Male',\n",
    "     'DEMEDU_2+ A levels or equivalents',\n",
    "     'DEMEDU_5+ GCSE, O-levels, 1 A level, or equivalents',\n",
    "     'DEMEDU_Apprenticeship', 'DEMEDU_No academic qualifications',\n",
    "     'DEMEDU_Other',\n",
    "     'DEMEDU_Undergraduate or postgraduate degree',\n",
    "     'DEMWRK_Retired', 'DEMWRK_Student',\n",
    "     'DEMWRK_Unable to work',\n",
    "     'DEMWRK_Unemployed',\n",
    "     'DEMWRK_Working full-time',\n",
    "     'DEMWRK_Working part-time',\n",
    "     'DEMREL_Christian', 'DEMREL_Muslim', 'DEMREL_Other',\n",
    "     'DEMINC_Under £15,000', 'DEMINC_£15,000 to £24,999',\n",
    "     'DEMINC_£25,000 to £34,999', 'DEMINC_£35,000 to £44,999',\n",
    "     'DEMINC_£45,000 to £54,999', 'DEMINC_£55,000 to £64,999',\n",
    "     'DEMINC_£65,000 to £99,999', 'COV_SHIELD_Yes',\n",
    "     'COV_TRUST_1_National television',\n",
    "     'COV_TRUST_2_Satellite / international television channels',\n",
    "     'COV_TRUST_3_Radio', 'COV_TRUST_4_Newspapers',\n",
    "     'COV_TRUST_5_Social media (Facebook, Twitter, etc)',\n",
    "     'COV_TRUST_6_National public health authorities (such as the NHS or Public Health England / Wales)',\n",
    "     'COV_TRUST_7_Healthcare workers',\n",
    "     'COV_TRUST_8_International health authorities (such as The World Health Organization)',\n",
    "     'COV_TRUST_9_Government websites',\n",
    "     'COV_TRUST_10_The internet or search engines',\n",
    "     'COV_TRUST_11_Family and friends',\n",
    "     'COV_TRUST_12_Work, school, or college',\n",
    "     'COV_TRUST_13_Other (please specify)', 'COV_VAC_SELF', 'target_1', 'target_2']\n",
    "\n",
    "# Manually dropping first columns using total column and feature lists\n",
    "drop_columns = []\n",
    "for column in data.columns:\n",
    "    if column not in var_list:\n",
    "        print(column)\n",
    "        drop_columns.append(column)\n",
    "        \n",
    "data.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7958ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5620110566391989"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining base accuracy.\n",
    "data['COV_VAC_SELF'].value_counts(normalize=True)\n",
    "y = data['COV_VAC_SELF']\n",
    "y.value_counts(normalize=True).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b13238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5388\n",
       "2    2874\n",
       "3     773\n",
       "4     552\n",
       "Name: COV_VAC_SELF, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d734ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['DEMAGE', 'VAC_DEC',  'COV_KNOWL_1', 'COV_KNOWL_2',\n",
    "     'COV_KNOWL_3', 'COV_KNOWL_4', 'COV_KNOWL_5', 'COV_KNOWL_6',\n",
    "     'COV_KNOWL_7', 'DREAD', 'ANX_1', 'ANX_2', 'ANX_3', 'ANX_4', 'ANX_5',\n",
    "     'ANX_6', 'DEMREG_East of England',\n",
    "     'DEMREG_Greater London', 'DEMREG_North East', 'DEMREG_North West',\n",
    "     'DEMREG_Northern Ireland', 'DEMREG_Scotland', 'DEMREG_South East',\n",
    "     'DEMREG_South West', 'DEMREG_Wales', 'DEMREG_West Midlands',\n",
    "     'DEMREG_Yorkshire and The Humber', 'DEMSEX_Male',\n",
    "     'DEMEDU_2+ A levels or equivalents',\n",
    "     'DEMEDU_5+ GCSE, O-levels, 1 A level, or equivalents',\n",
    "     'DEMEDU_Apprenticeship', 'DEMEDU_No academic qualifications',\n",
    "     'DEMEDU_Other',\n",
    "     'DEMEDU_Undergraduate or postgraduate degree',\n",
    "     'DEMWRK_Retired', 'DEMWRK_Student',\n",
    "     'DEMWRK_Unable to work',\n",
    "     'DEMWRK_Unemployed',\n",
    "     'DEMWRK_Working full-time',\n",
    "     'DEMWRK_Working part-time',\n",
    "     'DEMREL_Christian', 'DEMREL_Muslim', 'DEMREL_Other',\n",
    "     'DEMINC_Under £15,000', 'DEMINC_£15,000 to £24,999',\n",
    "     'DEMINC_£25,000 to £34,999', 'DEMINC_£35,000 to £44,999',\n",
    "     'DEMINC_£45,000 to £54,999', 'DEMINC_£55,000 to £64,999',\n",
    "     'DEMINC_£65,000 to £99,999', 'COV_SHIELD_Yes',\n",
    "     'COV_TRUST_1_National television',\n",
    "     'COV_TRUST_2_Satellite / international television channels',\n",
    "     'COV_TRUST_3_Radio', 'COV_TRUST_4_Newspapers',\n",
    "     'COV_TRUST_5_Social media (Facebook, Twitter, etc)',\n",
    "     'COV_TRUST_6_National public health authorities (such as the NHS or Public Health England / Wales)',\n",
    "     'COV_TRUST_7_Healthcare workers',\n",
    "     'COV_TRUST_8_International health authorities (such as The World Health Organization)',\n",
    "     'COV_TRUST_9_Government websites',\n",
    "     'COV_TRUST_10_The internet or search engines',\n",
    "     'COV_TRUST_11_Family and friends',\n",
    "     'COV_TRUST_12_Work, school, or college',\n",
    "     'COV_TRUST_13_Other (please specify)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d4277f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing - Train/test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=3)\n",
    "\n",
    "# Data scaling\n",
    "scaler = StandardScaler()\n",
    "Xstd_train = scaler.fit_transform(X_train)\n",
    "Xstd_test = scaler.transform(X_test)\n",
    "\n",
    "# Application of over and under sampling\n",
    "under = RandomUnderSampler(sampling_strategy= {1: 2000, 2: 2000})\n",
    "over = SMOTE(sampling_strategy = {3: 2000, 4:2000})\n",
    "\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_smote, y_smote = pipeline.fit_resample(Xstd_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89bd0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Modelling function. Returns all necessary metrics, appends to the score accumulator dictionary\n",
    "# and prints out model results.\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "def model_run(model, xtr, xte, ytr, yte):\n",
    "    \"\"\"Function to run multiclass model set on train and test data, and return summary results & predictions\n",
    "    (assigned to the score accumulation dictionary)\n",
    "    \n",
    "    :param model: Model with which to fit train data and generate test predictions\n",
    "    :param xtr: Train data predictor variables\n",
    "    :param xte: Test data predictor variables\n",
    "    :param ytr: Train data target variable\n",
    "    :param yte: Test data target variable\n",
    "    :return: test data predictions\"\"\"\n",
    "    \n",
    "    model.fit(xtr, ytr)\n",
    "    model_name = f'{model}'\n",
    "    train_acc = model.score(xtr, ytr)\n",
    "    meancrossval = cross_val_score(model, xtr, ytr, cv=skf).mean()\n",
    "    meancrossvalroc = cross_val_score(model, xtr, ytr, scoring='roc_auc_ovr', cv=skf).mean()\n",
    "    test_acc = model.score(xte, yte)\n",
    "    predictions = model.predict(xte)\n",
    "    \n",
    "    variance = predictions.var(axis=0).mean()\n",
    "    bias_sq = np.mean((yte - predictions.mean(axis=0))**2)\n",
    "    variance = round(variance, 4)\n",
    "    bias_sq = round(bias_sq, 4)\n",
    "    \n",
    "    varbias = variance + bias_sq\n",
    "    \n",
    "    metrics.precision_score(yte, predictions, average='weighted')\n",
    "    metrics.recall_score(yte, predictions, average='weighted')\n",
    "    metrics.f1_score(yte, predictions, average='weighted')\n",
    "    print(f'Training accuracy score: {train_acc}')\n",
    "    print(f'5-Fold Cross Val accuracy score: {meancrossval}')\n",
    "    print(f'Test accuracy score: {test_acc}')\n",
    "    print()\n",
    "    print(f'5-Fold Cross Val ROCAUC score: {meancrossvalroc}')\n",
    "    print(f\"ROC_AUC_SCORE Test: {roc_auc_score(yte, model.predict_proba(xte), multi_class='ovr')}\")\n",
    "    print()\n",
    "    print(confusion_matrix(yte, predictions))\n",
    "    print()\n",
    "    print(classification_report(yte, predictions))\n",
    "    print()\n",
    "    print()\n",
    "    print(f'Variance: {variance}')\n",
    "    print(f'Bias sq: {bias_sq}')\n",
    "    print(f'Variance/Bias: {varbias}')\n",
    "    \n",
    "    scores['Model Name'].append(model_name)\n",
    "    scores['Train Accuracy'].append(train_acc)\n",
    "    scores['Cross Validation Accuracy'].append(meancrossval)\n",
    "    scores['Test Accuracy'].append(test_acc)\n",
    "    scores['Test Precision'].append(metrics.precision_score(yte, predictions, average='weighted'))\n",
    "    scores['Test Recall'].append(metrics.recall_score(yte, predictions, average='weighted'))\n",
    "    scores['Test F1 Score'].append(metrics.f1_score(yte, predictions, average='weighted'))\n",
    "    scores['Cross Validation ROC AUC'].append(meancrossvalroc)\n",
    "    scores['Test ROC AUC Score'].append(roc_auc_score(yte, model.predict_proba(xte), multi_class='ovr'))\n",
    "    scores['Variance'].append(variance)\n",
    "    scores['Bias'].append(bias_sq)\n",
    "    scores['Variance/bias'].append(varbias)\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "740aeacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising model scores dictionary\n",
    "scores = {\n",
    "    'Model Name': [],\n",
    "    'Train Accuracy': [],\n",
    "    'Cross Validation Accuracy': [],\n",
    "    'Test Accuracy': [],\n",
    "    'Test Precision': [],\n",
    "    'Test Recall': [],\n",
    "    'Test F1 Score': [],\n",
    "    'Cross Validation ROC AUC': [],\n",
    "    'Test ROC AUC Score': [],\n",
    "    'Variance': [],\n",
    "    'Bias': [],\n",
    "    'Variance/bias': []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4361bd44",
   "metadata": {},
   "source": [
    "**MLP and Logistic Regression Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a1660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the models\n",
    "\n",
    "log = LogisticRegression(multi_class='ovr')\n",
    "clf = MLPClassifier(solver='lbfgs',\n",
    "                   alpha=0.5,\n",
    "                   hidden_layer_sizes=(8, 8, 8, 8, 8),\n",
    "                   activation='relu',\n",
    "                   random_state=1,\n",
    "                   batch_size='auto',\n",
    "                   max_iter=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21317c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(multi_class='ovr')\n",
      "Training accuracy score: 0.47\n",
      "5-Fold Cross Val accuracy score: 0.44975\n",
      "Test accuracy score: 0.45828988529718456\n",
      "\n",
      "5-Fold Cross Val ROCAUC score: 0.7245071875000001\n",
      "ROC_AUC_SCORE Test: 0.6671378008865614\n",
      "\n",
      "[[641 171 151 115]\n",
      " [210 125 141  99]\n",
      " [ 46  26  41  42]\n",
      " [ 15  11  12  72]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.59      0.64      1078\n",
      "           2       0.38      0.22      0.28       575\n",
      "           3       0.12      0.26      0.16       155\n",
      "           4       0.22      0.65      0.33       110\n",
      "\n",
      "    accuracy                           0.46      1918\n",
      "   macro avg       0.35      0.43      0.35      1918\n",
      "weighted avg       0.53      0.46      0.48      1918\n",
      "\n",
      "\n",
      "\n",
      "Variance: 1.3373\n",
      "Bias sq: 0.9084\n",
      "Variance/Bias: 2.2457\n",
      "\n",
      "-----------------------\n",
      "\n",
      "Model: MLPClassifier(alpha=0.5, hidden_layer_sizes=(8, 8, 8, 8, 8), max_iter=10000,\n",
      "              random_state=1, solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score: 0.610875\n",
      "5-Fold Cross Val accuracy score: 0.532125\n",
      "Test accuracy score: 0.4197080291970803\n",
      "\n",
      "5-Fold Cross Val ROCAUC score: 0.7713220833333333\n",
      "ROC_AUC_SCORE Test: 0.6161745685714102\n",
      "\n",
      "[[500 295 193  90]\n",
      " [133 219 149  74]\n",
      " [ 32  56  36  31]\n",
      " [ 10  15  35  50]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.46      0.57      1078\n",
      "           2       0.37      0.38      0.38       575\n",
      "           3       0.09      0.23      0.13       155\n",
      "           4       0.20      0.45      0.28       110\n",
      "\n",
      "    accuracy                           0.42      1918\n",
      "   macro avg       0.35      0.38      0.34      1918\n",
      "weighted avg       0.55      0.42      0.46      1918\n",
      "\n",
      "\n",
      "\n",
      "Variance: 1.0641\n",
      "Bias sq: 0.9735\n",
      "Variance/Bias: 2.0376000000000003\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Running Model comparison\n",
    "model_list = [log, clf]\n",
    "\n",
    "for model in model_list:\n",
    "    print(f'Model: {model}')\n",
    "    model_run(model, X_smote, Xstd_test, y_smote, y_test)\n",
    "    print()\n",
    "    print('-----------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77045088",
   "metadata": {},
   "source": [
    "**MLP and Logistic Regression Optimisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464f788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Net Grid search w.r.t ROC AUC\n",
    "# Note that the code has been commented to prevent accidentally running code requiring significant computational power\n",
    "\n",
    "# ne_params = {'alpha': [0.001, 0.5, 0.75, 0.99],\n",
    "#              'hidden_layer_sizes': [(20, 20, 20, 20), (15, 15, 15, 15), (10, 10, 10, 10), (5, 5, 5, 5), (10, 10, 10, 10, 10)],\n",
    "#              'activation': ['logistic', 'tanh', 'relu']}\n",
    "\n",
    "# ne = MLPClassifier(random_state=1, max_iter=10000)\n",
    "\n",
    "# ne_gr = GridSearchCV(ne, ne_params, scoring='roc_auc_ovr', n_jobs=2, cv=5, verbose=1)\n",
    "# ne_gr.fit(X_smote, y_smote)\n",
    "# ne_best = ne_gr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46511df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(ne_best, 'best_network.jlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00fd20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural = joblib.load('best_network.jlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42b3bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION Grid search w.r.t ROC AUC. \n",
    "# Note that the code has been commented to prevent accidentally running code requiring significant computational power\n",
    "\n",
    "\n",
    "\n",
    "# log_params = {'l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9, 0.99],\n",
    "#               'C': np.logspace(-3, 0, 50)}\n",
    "\n",
    "# log = LogisticRegression(multi_class='ovr', penalty='elasticnet', solver='saga', max_iter=1000)\n",
    "\n",
    "# reclog_gr = GridSearchCV(log, log_params, scoring='roc_auc_ovr', n_jobs=2, cv=5, verbose=1)\n",
    "# reclog_gr.fit(X_smote, y_smote)\n",
    "# logbest_rec = reclog_gr.best_estimator_\n",
    "# joblib.dump(logbest_rec, 'underoverlogopt.jlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d15d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logbest = joblib.load('underoverlogopt.jlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a081b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(C=0.044984326689694466, l1_ratio=0.75, max_iter=1000,\n",
      "                   multi_class='ovr', penalty='elasticnet', solver='saga')\n",
      "Training accuracy score: 0.46775\n",
      "5-Fold Cross Val accuracy score: 0.4505\n",
      "Test accuracy score: 0.47132429614181437\n",
      "\n",
      "5-Fold Cross Val ROCAUC score: 0.7238298958333333\n",
      "ROC_AUC_SCORE Test: 0.6748391267895785\n",
      "\n",
      "[[671 145 145 117]\n",
      " [214 119 141 101]\n",
      " [ 48  22  40  45]\n",
      " [ 16   9  11  74]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.62      0.66      1078\n",
      "           2       0.40      0.21      0.27       575\n",
      "           3       0.12      0.26      0.16       155\n",
      "           4       0.22      0.67      0.33       110\n",
      "\n",
      "    accuracy                           0.47      1918\n",
      "   macro avg       0.36      0.44      0.36      1918\n",
      "weighted avg       0.54      0.47      0.49      1918\n",
      "\n",
      "\n",
      "\n",
      "Variance: 1.3723\n",
      "Bias sq: 0.897\n",
      "Variance/Bias: 2.2693000000000003\n",
      "\n",
      "-----------------------\n",
      "\n",
      "Model: MLPClassifier(alpha=0.99, hidden_layer_sizes=(20, 20, 20, 20), max_iter=10000,\n",
      "              random_state=1)\n",
      "Training accuracy score: 0.7425\n",
      "5-Fold Cross Val accuracy score: 0.638625\n",
      "Test accuracy score: 0.44629822732012514\n",
      "\n",
      "5-Fold Cross Val ROCAUC score: 0.8499642708333333\n",
      "ROC_AUC_SCORE Test: 0.6144661656621535\n",
      "\n",
      "[[549 301 151  77]\n",
      " [173 227 111  64]\n",
      " [ 37  54  45  19]\n",
      " [ 13  35  27  35]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.51      0.59      1078\n",
      "           2       0.37      0.39      0.38       575\n",
      "           3       0.13      0.29      0.18       155\n",
      "           4       0.18      0.32      0.23       110\n",
      "\n",
      "    accuracy                           0.45      1918\n",
      "   macro avg       0.35      0.38      0.35      1918\n",
      "weighted avg       0.53      0.45      0.48      1918\n",
      "\n",
      "\n",
      "\n",
      "Variance: 0.9827\n",
      "Bias sq: 0.8545\n",
      "Variance/Bias: 1.8372000000000002\n",
      "\n",
      "-----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running Model comparison\n",
    "model_list = [logbest, neural]\n",
    "\n",
    "for model in model_list:\n",
    "    print(f'Model: {model}')\n",
    "    model_run(model, X_smote, Xstd_test, y_smote, y_test)\n",
    "    print()\n",
    "    print('-----------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b0f96",
   "metadata": {},
   "source": [
    "**Results Analysis**\n",
    "\n",
    "Results suggest that, as per the original analysis (See Wave 1 modelling and Wave 2 modelling notebooks), the logistic regression performs best on accuracy, precision and recall measures compared to other estimators - in this case, the MLP neural net model, even with gridsearch optimisation of parameters.\n",
    "\n",
    "Results for the classifier again suggest over fitting on the test data, with training accuracy and ROCAUC scores significantly higher than corresponding test scores. \n",
    "\n",
    "Meanwhile, Logistic train and test scores are somewhat more aligned, and the model, both optimised and not-optimised performs broadly in line with results elsewhere (see separate notebooks as per above). While the logistic regression here performs poorly with regard to accuracy, but scores well relative to the MLP classifier on the priority class 3 and 4 recall scores, and on ROC AUC. \n",
    "\n",
    "The similarity in findings here and in the main analysis, suggests that the impact of utilising both under and oversampling techniques on the training data is limited, while an MLP neural network model does not perform better than the preferred logistic regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
